# Ollama-web-frontend-demo

This project uses the ollama-js/express libs in node-js to communicate with the ollama API.

## Requirments
- Node.js
- Ollama

## Setup
1. Clone project locally
2. Run ````npm install```` to get the dependencies
3. The default port is ````3005````
4. The default ai model is ````qwen2.5:1.5b````

## Usage
1. Run ````npm start````
2. Open broswer and go to ````http://localhost:3005````